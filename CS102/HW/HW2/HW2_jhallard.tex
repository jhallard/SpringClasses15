%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Programming/Coding Assignment
% LaTeX Template
%
% This template has been downloaded from:
% http://www.latextemplates.com
%
% Original author:
% Ted Pavlic (http://www.tedpavlic.com)
%
% Note:
% The \lipsum[#] commands throughout this template generate dummy text
% to fill the template out. These commands should all be removed when 
% writing assignment content.
%
% This template uses a Perl script as an example snippet of code, most other
% languages are also usable. Configure them in the "CODE INCLUSION 
% CONFIGURATION" section.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%   PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}

\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage[usenames,dvipsnames]{color} % Required for custom colors
\usepackage{graphicx} % Required to insert images
\usepackage{listings} % Required for insertion of code
\usepackage{courier} % Required for the courier font
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{\hmwkAuthorName} % Top left header
\chead{\hmwkClass\ (\hmwkClassInstructor\ \hmwkClassTime): \hmwkTitle} % Top center head
\rhead{\firstxmark} % Top right header
\lfoot{\lastxmark} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Page\ \thepage\ of\ \protect\pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule
\newcommand{\tab}{\hspace*{3em}}

\setlength\parindent{0pt} % Removes all indentation from paragraphs

%----------------------------------------------------------------------------------------
%   CODE INCLUSION CONFIGURATION
%----------------------------------------------------------------------------------------

\definecolor{MyDarkGreen}{rgb}{0.0,0.4,0.0} % This is the color used for comments
\lstloadlanguages{Perl} % Load Perl syntax for listings, for a list of other languages supported see: ftp://ftp.tex.ac.uk/tex-archive/macros/latex/contrib/listings/listings.pdf
\lstset{language=Perl, % Use Perl in this example
        frame=single, % Single frame around code
        basicstyle=\small\ttfamily, % Use small true type font
        keywordstyle=[1]\color{Blue}\bf, % Perl functions bold and blue
        keywordstyle=[2]\color{Purple}, % Perl function arguments purple
        keywordstyle=[3]\color{Blue}\underbar, % Custom functions underlined and blue
        identifierstyle=, % Nothing special about identifiers                                         
        commentstyle=\usefont{T1}{pcr}{m}{sl}\color{MyDarkGreen}\small, % Comments small dark green courier font
        stringstyle=\color{Purple}, % Strings are purple
        showstringspaces=false, % Don't put marks in string spaces
        tabsize=5, % 5 spaces per tab
        %
        % Put standard Perl functions not included in the default language here
        morekeywords={rand},
        %
        % Put Perl function parameters here
        morekeywords=[2]{on, off, interp},
        %
        % Put user defined functions here
        morekeywords=[3]{test},
        %
        morecomment=[l][\color{Blue}]{...}, % Line continuation (...) like blue comment
        numbers=left, % Line numbers on left
        firstnumber=1, % Line numbers start with line 1
        numberstyle=\tiny\color{Blue}, % Line numbers are blue and small
        stepnumber=5 % Line numbers go in steps of 5
}

% Creates a new command to include a perl script, the first parameter is the filename of the script (without .pl), the second parameter is the caption
\newcommand{\perlscript}[2]{
\begin{itemize}
\item[]\lstinputlisting[caption=#2,label=#1]{#1.pl}
\end{itemize}
}

%----------------------------------------------------------------------------------------
%   DOCUMENT STRUCTURE COMMANDS
%   Skip this unless you know what you're doing
%----------------------------------------------------------------------------------------

% Header and footer for when a page split occurs within a problem environment
\newcommand{\enterProblemHeader}[1]{
\nobreak\extramarks{#1}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
}

% Header and footer for when a page split occurs between problem environments
\newcommand{\exitProblemHeader}[1]{
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1}{}\nobreak
}

\setcounter{secnumdepth}{0} % Removes default section numbers
\newcounter{homeworkProblemCounter} % Creates a counter to keep track of the number of problems

\newcommand{\homeworkProblemName}{}
\newenvironment{homeworkProblem}[1][Problem \arabic{homeworkProblemCounter}]{ % Makes a new environment called homeworkProblem which takes 1 argument (custom name) but the default is "Problem #"
\stepcounter{homeworkProblemCounter} % Increase counter for number of problems
\renewcommand{\homeworkProblemName}{#1} % Assign \homeworkProblemName the name of the problem
\section{\homeworkProblemName} % Make a section in the document with the custom problem count
\enterProblemHeader{\homeworkProblemName} % Header and footer within the environment
}{
\exitProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

\newcommand{\problemAnswer}[1]{ % Defines the problem answer command with the content as the only argument
\noindent\framebox[\columnwidth][c]{\begin{minipage}{0.98\columnwidth}#1\end{minipage}} % Makes the box around the problem answer and puts the content inside
}

\newcommand{\homeworkSectionName}{}
\newenvironment{homeworkSection}[1]{ % New environment for sections within homework problems, takes 1 argument - the name of the section
\renewcommand{\homeworkSectionName}{#1} % Assign \homeworkSectionName to the name of the section from the environment argument
\subsection{\homeworkSectionName} % Make a subsection with the custom name of the subsection
\enterProblemHeader{\homeworkProblemName} % Header and footer within the environment
}{
\enterProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

%----------------------------------------------------------------------------------------
%   NAME AND CLASS SECTION
%----------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Homework\ \#2} % Assignment title
\newcommand{\hmwkDueDate}{Tuesday,\ April\ 14,\ 2015} % Due date
\newcommand{\hmwkClass}{CMPS\ 102} % Course/class
\newcommand{\hmwkClassTime}{4:00pm} % Class/lecture time
\newcommand{\hmwkClassInstructor}{Warmuth} % Teacher/lecturer
\newcommand{\hmwkAuthorName}{John Allard \ 1437547
} % Your name


%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
%   USER SETTINGS
%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}



%----------------------------------------------------------------------------------------
%   TITLE PAGE
%----------------------------------------------------------------------------------------

\title{
\vspace{2in}
\textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
\normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate}\\
\vspace{0.1in}\large{\textit{}}
\vspace{3in}
}

\author{\textbf{\hmwkAuthorName}}
\date{} % Insert date here if you want it to appear below your name

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle

%----------------------------------------------------------------------------------------
%   TABLE OF CONTENTS
%----------------------------------------------------------------------------------------

%\setcounter{tocdepth}{1} % Uncomment this line if you don't want subsections listed in the ToC

% \tableofcontents
\newpage

%----------------------------------------------------------------------------------------
%   PROBLEM 1
%----------------------------------------------------------------------------------------

% To have just one problem per page, simply put a \clearpage after each problem

\begin{homeworkProblem}
 Design 3 algorithms based on binary min heaps that find the $k$th smallest \# out of a set of $n$ \#'s in time:
\begin{enumerate}
\item[a)] $O(n \log k)$
\item[b)] $O(n + k \log n)$
\item[c)] $O(n + k \log k)$
\end{enumerate}

Use the heap operations (here $s$ is the size):
\begin{itemize}
\item   Insert, delete: $O(\log s)$
\item   Buildheap: $O(s)$
\item   Smallest: $O(1)$
\end{itemize}
  
Give high level descriptions of the 3 algorithms and briefly reason correctness and running time. Part c) is the most challenging.


\begin{enumerate}

\item \textbf{Part A} - I found this to be a very wierd problem, any attempts to get the required run-time had me going out of my way to find a slower
than optimal algorithm. I know from looking at the runtime that we need to perform $n$ total insertion or deletion operations on a heap of size $k$, which would give runtime $O(n\log(k))$, but there didn't seem to be a natural way of doing so.

\item \textbf{Part B} - Designing an algorithm to run in $O(n + k\log(n))$ seemed the most inutive to me. My algorithm is like heapsort, except it stops after $k$ iterations, which reduces its run time from $O(n\log(n))$ to $O(n + k\log(n))$. \\[.15in]
\problemAnswer{
\texttt{// A = array of n elements of arbitray order} \\
\texttt{ 1.} \texttt{ findp(A) } \\
\texttt{ 2.} \texttt{ \tab BuildHeap(A) // O(n)} \\
\texttt{ 3.} \texttt{ \tab for i in [1..k-1] // O(k)} \\
\texttt{ 4.} \texttt{ \tab \tab Delete(A) // O(log(n))} \\
\texttt{ 5.} \texttt{ \tab return Smallest(A) // O(1)} \\
\texttt{ 6.} \texttt{ \tab // O(n) + O(k)*O(logn) + O(1)} \\
}

The algorithm starts by constructing a heap over all $n$ elements, which is where the $O(n)$ term comes from in the runtime. Now, we simply perform $k-1$ deletion operations, which each take $O(\log(n))$ time to complete. After these operations, the $k$th smallest element will be at the top of the heap, so we can perform a simple Smallest retrieval operation, which will give us the $k$th smallest element. Runtime - $O(n)$ for Buildheap, $O(k)$ iterations of delete-min at a cost of $O(\log(n))$ gives a total run-time of $O(n + k\log(n))$. \\


\item \textbf{Part C} - 

\end{enumerate}

\end{homeworkProblem}


%----------------------------------------------------------------------------------------
%   PROBLEM 2
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}

Consider the following sorting algorithm for an array of numbers (Assume the size $n$ of the array is divisible by 3):
\begin{itemize}
\item   Sort the initial 2/3 of the array.
\item   Sort the final 2/3 and then again the initial 2/3.
\end{itemize}

Reason that this algorithm properly sorts the array. What is its running time?

\textbf{Proof of Correctness} \\
 I am assuming that this is a recursive definition, and that we recurse until we reach two elements at which point we just swap them into place with a single operation. Let $P(n)$ be the statement `for $n \geq 1$, an array $A$ of length $n$ on elements of arbitrary order will be corectly sorted by the 2/3rds sorting algorithm.'

 \textbf{Base Case} \\
 $P(n=1)$ - If $n=1$, there is only one element to be sorted so we just return the array. Confirmed.\\
 $P(n=2)$ - If $n=2$. no recursion is needed, we simply perform a single comparison and swap the items into place, then return the array. Confirmed. \\
 % $P(n=3)$ - If $n=3$, then we need to recurse once. Call the three indices of the array $A_1, A_2,$ and $A_3$. The algorithm will start by recursing on the first two elements, which will perform a single comparison and swap them into place. We now know that whichever element is in $A_2$ is greater or equal to the element in index $A_1$. Next, we recurse on elements $A_2$ and $A_3$, swapping them into place. After this operation, whatever element is in index $A_3$ is greater than what is in $A_2$, and by extension of the result of the last recursive call, the value in $A_3$ is in the correct place (greater or equal to both other elements). Because $A_3$ is correct, we know that $A_1$ and $A_2$ contain the smallest and middle values of the array, but possibly out of order. One final recursive call on $A_1$ and $A_2$ swaps these two final elements into correct order, and the array is now sorted. \\

 \textbf{Inductive Step} \\
 For $n \geq 3$ where n is a multiple of 3, assume that $P(k)$ is true for $3 \leq k \leq n$, i.e. that an array of length $k$ can be sorted correctly by the given sorting algorithm. \\
 Start with an array of size $n+3$ (the next multiple of 3). Let $A_1, A_2,$ and $A_3$ represent the 1st, 2nd, and final thirds of the array indices. 
 On the first call we attempt to recurse on $A_1 \cup A_2$.
 Because this sub-array is of size $\frac{2}{3} (n+3)$, which is less than or equal to $n$ for $n \geq 3$, we can apply the inductive hypothesis on this subarray. \\
 After applying the inductive hypothesis, $A_1 \cup A_2$ will be sorted properly, and thus all of the elements in $A_2$ will be at least as great as the elements in $A_1$.
 $$\forall x \in A_1, y \in A_2, x \leq y \tab (1)$$ 
 We then recurse on $A_2 \cup A_3$, once again the inductive hypothesis applies by the same argument given above, which means $A_2 \cup A_3$ is sorted.
 This implies that all elements in $A_3$ are at least as great as those in $A_2$.
  $$\forall x \in A_2, y \in A_3, x \leq y \tab (2)$$ 
 If you combine this fact with the result of the last recursive call (1), we deduce the following :
   $$\forall x \in A_1 \cup A_2, y \in A_3, x \leq y \tab (3)$$ 
 This means that all elements in $A_3$ are in the right place. The final 3rd of the array being in the right place implies that all of the elements in the indices $A_1 \cup A_2$ belong in that first 2/3rds of the array, but they are possbily scattered and out of orderby our last sorting call. \\
 With one final recursive call on $A_1 \cup A_2$, our inductive hypothesis once again applies and (1) is restored. (3) is still valid because the last sort only rearranged items in $A_1$ and $A_2$, which were all less than or equal to items in $A_3$ to begin with. Combining (1) and (3) : \\
 $$\forall x \in A_1, y \in A_2, z \in A_3, x \leq y \leq z \tab (4)$$
 Add to this the fact that the individual thirds are correctly sorted internally (by our ind. hyp.), and we have shown that the entire array of $n+3$ elements has been properly sorted. /// \\

\textbf{Runtime} \\
This algorithm is slightly odd be it does almost no work while dividing nor when recombining. When we get down to a length less than 3, we simply compare pairs of elements are swap them if necessary. Only at the bottom level do we perform any comparisons, on every other level we simply recurse 3 times on an input of size 2/3rds the current sub-array size. Thus the recurrence is : \\
    \[
    T(n) \left \{
      \begin{tabular}{c l}
      $= O(1)$ & if  $1 \leq n \leq 2$ \\
      $\leq$ 3T(2n/3) + O(1) & \text{ if } $n \geq 3$  \\
      \end{tabular}
    \right \}
    \]

    We can apply the master theorum with $a = 3$, $b=3/2$, and $f(n) = O(1)$. $\log_b(a) = log_{\frac{3}{2}}(3) = 2.7095$. The exponent on $f$ is $0$, so $f = O(n^{\log_b(a)-\epsilon})$, thus we are in case A of the master theorem. This means that :
    $$ T(n) = \Theta(n^{\log_{1.5}(3)} = n^{2.7095}) $$ ///


\end{homeworkProblem}


\begin{homeworkProblem}

KT, problem 1, p 246. :
You are interested in analyzing some hard-to-obtain data from two separate databases. Each database contains n numerical values, so there are 2n values total and you may assume that no two values are the same. You’d like to determine the median of this set of 2n values, which we will define here to be the nth smallest value. \\
However, the only way you can access these values is through queries to the databases. In a single query, you can specify a value k to one of the two databases, and the chosen database will return the kth smallest value that it contains. Since queries are expensive, you would like to compute the median using as few queries as possible. \\

Give an algorithm that finds the median value using at most O(log n) queries \\
Since I am required to write an algorithm that runs in $O(\log n)$ quries, I know that I have to divide my search space by a constant multiple every constant number of queries, like how bianry search narrows the search space by a factor of a half every iteration. Like binary search, I'll start by looking in the middle of the data sets, which is the $\frac{n}{2}$ smallest number in each database of size $n$. The key idea that I'll use is that the median of the data set has to have a value that is between the medians of the individual data-sets. This is because if get the $\frac{n}{2}$ smallest number from both data-sets, we know there are at minimum going to be n-numbers smaller than the greater of the two medians. I'll go into this in more detail in the proof of correctness. \\ 

\problemAnswer{
\texttt{// db\_n = data base \#n} \\
\texttt{// db\_query(k, db\_n) returns the kth smallest item in db\_n } \\
\texttt{ 1.} \texttt{ FindMedian(db\_1, db\_2, n) } \\
\texttt{ 2.} \texttt{ \tab ind\_1 = n/2; // get the median value \#1 } \\
\texttt{ 2.} \texttt{ \tab ind\_2 = n/2; // get the median value \#2} \\
\texttt{ 3.} \texttt{ \tab for k in [1..log(n)] // log(n) iterations to find median} \\
\texttt{ 4.} \texttt{ \tab \tab } \\
\texttt{ 5.} \texttt{ \tab return Smallest(A) // O(1)} \\
\texttt{ 6.} \texttt{ \tab // O(n) + O(k)*O(logn) + O(1)} \\
}

\end{homeworkProblem}



\begin{homeworkProblem}

Suppose you are choosing between the following 3 algorithms:
\begin{enumerate}
\item Algorithm $A$ solves problems by dividing them into 5 subproblems of half the size, recursively solving each subproblem, and then combining the solutions in linear time.
\item Algorithm $B$ solves problems of size n by recursively solving 2 subproblems of size $n-1$ and the combining the solutions in constant time.
\item Algorithm $C$ solves problems of size $n$ by dividing them into nine subproblems of size $n/3$, recursively solving each subproblem, and the combining the solution in $O(n^2)$ time.
\end{enumerate}

What are the running times of each of these algs. (in big-O notation), and which would you choose?


\end{homeworkProblem}



\begin{homeworkProblem}

 The \textit{Hadamard matrices} $H_0, H_1, H_2, \ldots$ are defined as follows:
\begin{itemize}
\item $H_0$ is the $1 \times 1$ matrix $[1]$
\item For $k>0, H_k$ is the $2^k \times 2^k$ matrix
\end{itemize}
\begin{displaymath}
H_k =
\begin{bmatrix}
H_{k-1} & H_{k-1} \\
H_{k-1} & -H_{k-1} 
\end{bmatrix}
\end{displaymath}
Show that if $v$ is a column vector of length $n = 2^k$, then the matrix-vector product $H_kv$ can be calculated using $O(n \log n)$ operations. Assume that all the numbers involved are small enough that basic arithmetic operations like addition and multiplication take unit time.


\end{homeworkProblem}

\begin{homeworkProblem}

 \textbf{(Extra Credit)} The square of a matrix $A$ is its product with itself, $A A$.

\begin{enumerate}
\item Show that 5 multiplications are sufficient to compute the square of a $2 \times 2$ matrix.
\item What is wrong with the following algorithm for computing the square of an $n \times n$ matrix.\\
``Use a divide-and-conquer approach as in Strassen's algorithm, except that instead of getting 7 subproblems of size $n/2$, we now get 5 subproblems of size $n/2$ thanks to part a). Using the same analysis as in Strassen's algorithm we can conclude that the algorithm runs in time $O(n^{\log_2 5})$.''
\item In fact, squaring matrices is no easier that matrix multiplication. Show that if $n \times n$ matrices can be squared in time $O(n^c)$, then any two $n \times n$ matrices can be multiplied in time $O(n^c)$.
\end{enumerate}

\end{homeworkProblem}

%----------------------------------------------------------------------------------------

\end{document}